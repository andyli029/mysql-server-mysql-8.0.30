/*
 * This file is open source software, licensed to you under the terms
 * of the Apache License, Version 2.0 (the "License").  See the NOTICE file
 * distributed with this work for additional information regarding copyright
 * ownership.  You may not use this file except in compliance with the License.
 *
 * You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

/*
 * Copyright (C) 2016 ScyllaDB
 * Copyright (c) 2022 StoneAtom, Inc. All rights reserved.
 */
#ifndef TIANMU_BASE_FAIR_QUEUE_H_
#define TIANMU_BASE_FAIR_QUEUE_H_
#pragma once

#include <chrono>
#include <cmath>
#include <experimental/optional>
#include <queue>
#include <type_traits>
#include <unordered_set>

#include "base/core/circular_buffer.h"
#include "base/core/future.h"
#include "base/core/print.h"
#include "base/core/semaphore.h"
#include "base/core/shared_ptr.h"

namespace Tianmu {
namespace base {
/// \addtogroup io-module
/// @{

/// \cond internal
class priority_class {
  struct request {
    promise<> pr;
    unsigned weight;
  };
  friend class fair_queue;
  uint32_t _shares = 0;
  float _accumulated = 0;
  circular_buffer<request> _queue;
  bool _queued = false;

  friend struct shared_ptr_no_esft<priority_class>;
  explicit priority_class(uint32_t shares) : _shares(shares) {}
};
/// \endcond

/// \brief Priority class, to be used with a given \ref fair_queue
///
/// An instance of this class is associated with a given \ref fair_queue. When
/// registering a class, the caller will receive a \ref lw_shared_ptr to an
/// object of this class. All its methods are private, so the only thing the
/// caller is expected to do with it is to pass it later to the \ref fair_queue
/// to identify a given class.
///
/// \related fair_queue
using priority_class_ptr = lw_shared_ptr<priority_class>;

/// \brief Fair queuing class
///
/// This is a fair queue, allowing multiple request producers to queue requests
/// that will then be served proportionally to their classes' shares.
///
/// To each request, a weight can also be associated. A request of weight 1 will
/// consume 1 share. Higher weights for a request will consume a proportionally
/// higher amount of shares.
///
/// The user of this interface is expected to register multiple \ref
/// priority_class objects, which will each have a shares attribute.
///
/// Internally, each priority class may keep a separate queue of requests.
/// Requests pertaining to a class can go through even if they are over its
/// share limit, provided that the other classes have empty queues.
///
/// When the classes that lag behind start seeing requests, the fair queue will
/// serve them first, until balance is restored. This balancing is expected to
/// happen within a certain time window that obeys an exponential decay.
class fair_queue {
  friend priority_class;

  struct class_compare {
    bool operator()(const priority_class_ptr &lhs, const priority_class_ptr &rhs) const {
      return lhs->_accumulated > rhs->_accumulated;
    }
  };

  semaphore _sem;
  unsigned _capacity;
  using clock_type = std::chrono::steady_clock::time_point;
  clock_type _base;
  std::chrono::microseconds _tau;
  using prioq = std::priority_queue<priority_class_ptr, std::vector<priority_class_ptr>, class_compare>;
  prioq _handles;
  std::unordered_set<priority_class_ptr> _all_classes;

  void push_priority_class(priority_class_ptr pc) {
    if (!pc->_queued) {
      _handles.push(pc);
      pc->_queued = true;
    }
  }

  priority_class_ptr pop_priority_class() {
    assert(!_handles.empty());
    auto h = _handles.top();
    _handles.pop();
    assert(h->_queued);
    h->_queued = false;
    return h;
  }

  void execute_one() {
    _sem.wait().then([this] {
      priority_class_ptr h;
      do {
        h = pop_priority_class();
      } while (h->_queue.empty());

      auto req = std::move(h->_queue.front());
      h->_queue.pop_front();

      req.pr.set_value();
      auto delta = std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - _base);
      auto req_cost = float(req.weight) / h->_shares;
      auto cost = expf(1.0f / _tau.count() * delta.count()) * req_cost;
      float next_accumulated = h->_accumulated + cost;
      while (std::isinf(next_accumulated)) {
        normalize_stats();
        // If we have renormalized, our time base will have changed. This should
        // happen very infrequently
        delta = std::chrono::duration_cast<std::chrono::microseconds>(std::chrono::steady_clock::now() - _base);
        cost = expf(1.0f / _tau.count() * delta.count()) * req_cost;
        next_accumulated = h->_accumulated + cost;
      }
      h->_accumulated = next_accumulated;

      if (!h->_queue.empty()) {
        push_priority_class(h);
      }
      return make_ready_future<>();
    });
  }

  float normalize_factor() const { return std::numeric_limits<float>::min(); }

  void normalize_stats() {
    auto time_delta = std::log(normalize_factor()) * _tau;
    // time_delta is negative; and this may advance _base into the future
    _base -= std::chrono::duration_cast<clock_type::duration>(time_delta);
    for (auto &pc : _all_classes) {
      pc->_accumulated *= normalize_factor();
    }
  }

 public:
  /// Constructs a fair queue with a given \c capacity.
  ///
  /// \param capacity how many concurrent requests are allowed in this queue.
  /// \param tau the queue exponential decay parameter, as in exp(-1/tau * t)
  explicit fair_queue(unsigned capacity, std::chrono::microseconds tau = std::chrono::milliseconds(100))
      : _sem(capacity), _capacity(capacity), _base(std::chrono::steady_clock::now()), _tau(tau) {}

  /// Registers a priority class against this fair queue.
  ///
  /// \param shares, how many shares to create this class with
  priority_class_ptr register_priority_class(uint32_t shares) {
    priority_class_ptr pclass = make_lw_shared<priority_class>(shares);
    _all_classes.insert(pclass);
    return pclass;
  }

  /// Unregister a priority class.
  ///
  /// It is illegal to unregister a priority class that still have pending
  /// requests.
  void unregister_priority_class(priority_class_ptr pclass) {
    assert(pclass->_queue.empty());
    _all_classes.erase(pclass);
  }

  /// \return how many waiters are currently queued for all classes.
  size_t waiters() const { return _sem.waiters(); }

  /// Executes the function \c func through this class' \ref fair_queue, with
  /// weight \c weight
  ///
  /// \return \c func's return value, if \c func returns a future, or future<T>
  /// if \c func returns a non-future of type T.
  template <typename Func>
  futurize_t<std::result_of_t<Func()>> queue(priority_class_ptr pc, unsigned weight, Func func) {
    // We need to return a future in this function on which the caller can wait.
    // Since we don't know which queue we will use to execute the next request -
    // if ours or someone else's, we need a separate promise at this point.
    promise<> pr;
    auto fut = pr.get_future();

    push_priority_class(pc);
    pc->_queue.push_back(priority_class::request{std::move(pr), weight});
    try {
      execute_one();
    } catch (...) {
      pc->_queue.pop_back();
      throw;
    }
    return fut.then([func = std::move(func)] { return func(); }).finally([this] { _sem.signal(); });
  }

  /// Updates the current shares of this priority class
  ///
  /// \param new_shares the new number of shares for this priority class
  static void update_shares(priority_class_ptr pc, uint32_t new_shares) { pc->_shares = new_shares; }
};
/// @}

}  // namespace base
}  // namespace Tianmu

#endif  // TIANMU_BASE_FAIR_QUEUE_H_
